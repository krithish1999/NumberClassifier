{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 25)                525       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 17,735\n",
      "Trainable params: 17,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense ,Activation\n",
    "import numpy as np\n",
    "import keras\n",
    "model = Sequential()\n",
    "model.add(Dense(20,input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "keras.layers.Dropout(10)\n",
    "model.compile(optimizer='rmsprop',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 48s 4us/step\n",
      "11501568/11490434 [==============================] - 48s 4us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_x, train_y) , (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x1 =  train_x[:1000,:]\n",
    "test_x1 = test_x[:500,:]\n",
    "train_y1 = train_y[:1000,:]\n",
    "test_y1 = test_y[:500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 0s 323us/step - loss: 1.7971 - acc: 0.8280\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8237 - acc: 0.8622\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.3713 - acc: 0.9003\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.2909 - acc: 0.9110\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.2656 - acc: 0.9148\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.2460 - acc: 0.9190\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.2299 - acc: 0.9239\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.2094 - acc: 0.9283\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1945 - acc: 0.9340\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.1796 - acc: 0.9377\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1703 - acc: 0.9434\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1540 - acc: 0.9481\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1452 - acc: 0.9502\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1369 - acc: 0.9526\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1311 - acc: 0.9531\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1202 - acc: 0.9571\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1080 - acc: 0.9617\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0970 - acc: 0.9656\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0887 - acc: 0.9688\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0823 - acc: 0.9703\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0731 - acc: 0.9729\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0700 - acc: 0.9751\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0727 - acc: 0.9724\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0632 - acc: 0.9775\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0581 - acc: 0.9782\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0594 - acc: 0.9780\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0570 - acc: 0.9781\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0550 - acc: 0.9791\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0483 - acc: 0.9817\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0431 - acc: 0.9828\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0422 - acc: 0.9822\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0405 - acc: 0.9830\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0379 - acc: 0.9842\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0363 - acc: 0.9841\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0372 - acc: 0.9835\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0351 - acc: 0.9832\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.985 - 0s 29us/step - loss: 0.0299 - acc: 0.9845\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0284 - acc: 0.9852\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0279 - acc: 0.9934\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0247 - acc: 0.9945\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0342 - acc: 0.9922\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0229 - acc: 0.9939\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0222 - acc: 0.9940\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0211 - acc: 0.9948\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0175 - acc: 0.9953\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0183 - acc: 0.9956\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0261 - acc: 0.9925\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0197 - acc: 0.9948\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0157 - acc: 0.9957\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0140 - acc: 0.9960\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0254 - acc: 0.9919\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0158 - acc: 0.9952\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0151 - acc: 0.9956\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0128 - acc: 0.9962\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0142 - acc: 0.9960\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0150 - acc: 0.9946\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0122 - acc: 0.9965\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0116 - acc: 0.9967\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0105 - acc: 0.9967\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0105 - acc: 0.9960\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0119 - acc: 0.9962\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0099 - acc: 0.9967\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0085 - acc: 0.9973\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.996 - 0s 36us/step - loss: 0.0167 - acc: 0.9959\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0175 - acc: 0.9950\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0103 - acc: 0.9959\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0063 - acc: 0.9980\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0073 - acc: 0.9974\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0068 - acc: 0.9978\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0105 - acc: 0.9970\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0068 - acc: 0.9978\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0111 - acc: 0.9961\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0097 - acc: 0.9966\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0122 - acc: 0.9959\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0159 - acc: 0.9962\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0086 - acc: 0.9977\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0081 - acc: 0.9978\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0067 - acc: 0.9978\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0056 - acc: 0.9982\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0065 - acc: 0.9985\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0069 - acc: 0.9981\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0193 - acc: 0.9948\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0058 - acc: 0.9987\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0055 - acc: 0.9988\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0073 - acc: 0.9981\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0050 - acc: 0.9986\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0049 - acc: 0.9989\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0053 - acc: 0.9985\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0053 - acc: 0.9985\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0152 - acc: 0.9971\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0054 - acc: 0.9986\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0036 - acc: 0.9991\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0135 - acc: 0.9972\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0089 - acc: 0.9982\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0087 - acc: 0.9984\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0083 - acc: 0.9982\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0154 - acc: 0.9975\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0030 - acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb40c1d1990>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x1,train_y1,epochs=200,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 157us/step\n",
      "[0.4495082855224609, 0.9528000354766846]\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_x1,test_y1,batch_size=100)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 14us/step\n",
      "[0.004640254055539117, 0.9992000043392182]\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = model.evaluate(train_x1,train_y1,batch_size=100)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(test_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.to_categorical(train_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1572 - acc: 0.9498\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0917 - acc: 0.9655\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0811 - acc: 0.9678\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0751 - acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4382e7f50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,epochs=4,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(10000,784)\n",
    "test_y = keras.utils.to_categorical(test_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/step\n"
     ]
    }
   ],
   "source": [
    "accuray = model.evaluate(test_x,test_y,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392921875\n"
     ]
    }
   ],
   "source": [
    "a = np.max(model.predict(test_x),axis =1)\n",
    "print(np.sum(a)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 17,160\n",
      "Trainable params: 17,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07528310706838966, 0.9691899937391281]\n"
     ]
    }
   ],
   "source": [
    "print(accuray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_x[3]\n",
    "image1 = img.reshape((1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Class :', 4)\n"
     ]
    }
   ],
   "source": [
    "img_class = model.predict_classes(image1)\n",
    "classname = img_class[0]\n",
    "print(\"Class :\",classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = img.reshape((28,28))\n",
    "plt.imshow(img)\n",
    "plt.title(classname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step\n",
      "[0.07124376927812894, 0.9696183327833812]\n"
     ]
    }
   ],
   "source": [
    "accuray1 = model.evaluate(train_x,train_y,batch_size=100)\n",
    "print(accuray1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366612630208333\n"
     ]
    }
   ],
   "source": [
    "b = np.max(model.predict(train_x),axis=1)\n",
    "print(np.sum(b)/len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
